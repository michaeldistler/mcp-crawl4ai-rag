# The transport for the MCP server - either 'sse' or 'stdio' (defaults to sse if left empty)
TRANSPORT=

# Host to bind to if using sse as the transport (leave empty if using stdio)
# Set this to 0.0.0.0 if using Docker, otherwise set to localhost (if using uv)
HOST=

# Port to listen on if using sse as the transport (leave empty if using stdio)
PORT=

# Get your Open AI API Key by following these instructions -
# https://help.openai.com/en/articles/4936850-where-do-i-find-my-openai-api-key
# This is for the embedding model - text-embed-small-3 will be used
OPENAI_API_KEY=

# The LLM you want to use for summaries and contextual embeddings
# Generally this is a very cheap and fast LLM like gpt-4o-mini
MODEL_CHOICE=

# LLM Provider Configuration
# Choose which LLM provider to use: "openai", "anthropic", or "ollama"
LLM_PROVIDER=openai

# Default LLM model to use (provider-specific)
# OpenAI: gpt-4o-mini, gpt-4o, gpt-3.5-turbo, etc.
# Anthropic: claude-3-5-sonnet-20241022, claude-3-haiku-20240307, etc.
# Ollama: llama3.2, mistral, codellama, etc. (must be installed locally)
LLM_MODEL=gpt-4o-mini

# Embedding Provider Configuration
# Choose which embedding provider to use: "openai", "ollama", or "sentence_transformers"
EMBEDDING_PROVIDER=openai

# OpenAI Embedding Model (when using OpenAI as embedding provider)
# Options: text-embedding-3-small, text-embedding-3-large, text-embedding-ada-002
OPENAI_EMBEDDING_MODEL=text-embedding-3-small

# Anthropic API Key (required if using Anthropic as LLM provider)
# Get your key from: https://console.anthropic.com/
ANTHROPIC_API_KEY=

# Ollama Configuration (required if using Ollama as LLM or embedding provider)
# Base URL for your Ollama instance
OLLAMA_BASE_URL=http://localhost:11434

# Ollama embedding model (when using Ollama as embedding provider)
# Popular options: nomic-embed-text, mxbai-embed-large, etc.
OLLAMA_EMBEDDING_MODEL=nomic-embed-text

# Ollama embedding dimension (depends on your chosen model)
OLLAMA_EMBEDDING_DIMENSION=768

# Sentence Transformers Configuration (for local embeddings)
# Model name from Hugging Face (when using sentence_transformers as embedding provider)
# Popular options: all-MiniLM-L6-v2, all-mpnet-base-v2, etc.
SENTENCE_TRANSFORMERS_MODEL=all-MiniLM-L6-v2

# RAG strategies - set these to "true" or "false" (default to "false")
# USE_CONTEXTUAL_EMBEDDINGS: Enhances embeddings with contextual information for better retrieval
USE_CONTEXTUAL_EMBEDDINGS=false

# USE_HYBRID_SEARCH: Combines vector similarity search with keyword search for better results
USE_HYBRID_SEARCH=false

# USE_AGENTIC_RAG: Enables code example extraction, storage, and specialized code search functionality
USE_AGENTIC_RAG=false

# USE_RERANKING: Applies cross-encoder reranking to improve search result relevance
USE_RERANKING=false

# USE_KNOWLEDGE_GRAPH: Enables AI hallucination detection and repository parsing tools using Neo4j
# If you set this to true, you must also set the Neo4j environment variables below.
USE_KNOWLEDGE_GRAPH=false

# PostgreSQL Configuration for RAG database
# These settings configure the PostgreSQL database with pgvector extension for vector storage and search

# PostgreSQL host - use localhost for local development, or your PostgreSQL server hostname
POSTGRES_HOST=localhost

# PostgreSQL port - default is 5432
POSTGRES_PORT=5432

# Name of the database to use - will be created if it doesn't exist
POSTGRES_DB=crawl4ai_rag

# PostgreSQL username for authentication
POSTGRES_USER=postgres

# PostgreSQL password for the specified user
POSTGRES_PASSWORD=

# Neo4j Configuration for Knowledge Graph Tools
# These are required for the AI hallucination detection and repository parsing tools
# Leave empty to disable knowledge graph functionality

# Neo4j connection URI - use bolt://localhost:7687 for local, neo4j:// for cloud instances
# IMPORTANT: If running the MCP server through Docker, change localhost to host.docker.internal
NEO4J_URI=bolt://localhost:7687

# Neo4j username (usually 'neo4j' for default installations)
NEO4J_USER=neo4j

# Neo4j password for your database instance
NEO4J_PASSWORD=